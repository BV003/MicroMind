LLM可训练总参数量：25.830 百万
Epoch:[1/1](0/44160) loss:8.933 lr:0.000550000000 epoch_Time:512.0min:
Epoch:[1/1](100/44160) loss:6.460 lr:0.000549993674 epoch_Time:52.0min:
Traceback (most recent call last):
  File "/root/home/MicroMind/trainer/train_pretrain.py", line 198, in <module>
    train_epoch(epoch, wandb)
  File "/root/home/MicroMind/trainer/train_pretrain.py", line 54, in train_epoch
    scaler.scale(loss).backward()
  File "/root/miniconda3/envs/micromind/lib/python3.10/site-packages/torch/_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "/root/miniconda3/envs/micromind/lib/python3.10/site-packages/torch/autograd/__init__.py", line 267, in backward
    _engine_run_backward(
  File "/root/miniconda3/envs/micromind/lib/python3.10/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
Traceback (most recent call last):
  File "/root/home/MicroMind/trainer/train_pretrain.py", line 198, in <module>
    train_epoch(epoch, wandb)
  File "/root/home/MicroMind/trainer/train_pretrain.py", line 54, in train_epoch
    scaler.scale(loss).backward()
  File "/root/miniconda3/envs/micromind/lib/python3.10/site-packages/torch/_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "/root/miniconda3/envs/micromind/lib/python3.10/site-packages/torch/autograd/__init__.py", line 267, in backward
    _engine_run_backward(
  File "/root/miniconda3/envs/micromind/lib/python3.10/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
